{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-class Vnet on BV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import *\n",
    "from vnet import *\n",
    "from training import *\n",
    "from niiutility import show_image, show_batch_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup Torch Global Variable, load memory map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#------------------------------- GLOBAL VARIABLES -------------------------------------#\n",
    "\n",
    "USE_GPU = True\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 6\n",
    "NUM_TRAIN = 80\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------LOAD THE DATA SET-------------------------------------------#\n",
    "regen = False\n",
    "\n",
    "if regen:\n",
    "\n",
    "    data_index = np.arange(107)\n",
    "    data_index = np.delete(data_index, 46)\n",
    "    data_idnex = np.random.shuffle(data_index)\n",
    "else:\n",
    "    data_index = np.array ([50,17,81,39,36,88,33,77,7,1,52,43,34,40,41,18,72,58,51,\n",
    "                  63,78,35,16,79,0,89,70,67,60,13,76,8,2,47,4,97,29,85,32,\n",
    "                  55,30,49,44,11,101,22,37,10,92,68,5,64,105,95,20,38,99,\n",
    "                  84,86,91,96,71,98,104,45,69,103,27,19,59,73,106,93,24,80,\n",
    "                  66,28,90,3,102,31,26,94,62,54,48,12,61,87,42,65,74,53,57,\n",
    "                  14,56,83,100,25,6,75,82,23,9,21,15])\n",
    "    \n",
    "dataset_trans = BvMaskDataset(data_index, \n",
    "                         transform=transforms.Compose([\n",
    "                             downSample(2),\n",
    "                             RandomFilp(0.5),\n",
    "                             RandomAffine(180, 15)\n",
    "                         ])\n",
    "                     )\n",
    "\n",
    "#-------------------------CREATE DATA LOADER FOR TRAIN AND VAL------------------------#\n",
    "\n",
    "data_size = len(dataset_trans)\n",
    "train_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE, \\\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE,\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,data_size)),\\\n",
    "                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print first 4 batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint 'checkpoint2019-04-05 19:46:58.793496.pth'\n",
      "loaded checkpoint 'checkpoint2019-04-05 19:46:58.793496.pth' (epoch 701)\n"
     ]
    }
   ],
   "source": [
    "from vnet import LNet\n",
    "\n",
    "LoadCKP = True\n",
    "\n",
    "CKPPath = 'checkpoint2019-04-05 19:46:58.793496.pth'\n",
    "\n",
    "model = LNet(img_size=(96, 128, 128), out_size=6)\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, verbose=True)\n",
    "\n",
    "if LoadCKP:\n",
    "    model, optimizer, scheduler = loadckp(model, optimizer, scheduler, CKPPath, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701 finished ! Training Loss: 207.0958251953125\n",
      "     validation loss = 222.0139\n",
      "Epoch 702 finished ! Training Loss: 200.1828621758355\n",
      "     validation loss = 93.8115\n",
      "Epoch 703 finished ! Training Loss: 171.88488939073352\n",
      "     validation loss = 102.4838\n",
      "Epoch 704 finished ! Training Loss: 171.37626139322916\n",
      "     validation loss = 105.9510\n",
      "Epoch 705 finished ! Training Loss: 189.24322424994574\n",
      "     validation loss = 118.0190\n",
      "Epoch 706 finished ! Training Loss: 174.1217778523763\n",
      "     validation loss = 88.8087\n",
      "Epoch 707 finished ! Training Loss: 174.5380342271593\n",
      "     validation loss = 102.0236\n",
      "Epoch 708 finished ! Training Loss: 184.65301767985025\n",
      "     validation loss = 190.2569\n",
      "Epoch 709 finished ! Training Loss: 169.331295437283\n",
      "     validation loss = 145.6956\n",
      "Epoch 710 finished ! Training Loss: 197.8787138197157\n",
      "     validation loss = 120.7738\n",
      "Epoch 711 finished ! Training Loss: 161.75042639838324\n",
      "     validation loss = 81.5241\n",
      "Epoch 712 finished ! Training Loss: 160.78707631429037\n",
      "     validation loss = 122.5199\n",
      "Epoch 713 finished ! Training Loss: 164.17950100368924\n",
      "     validation loss = 116.8110\n",
      "Epoch 714 finished ! Training Loss: 195.44705200195312\n",
      "     validation loss = 85.5683\n",
      "Epoch 715 finished ! Training Loss: 148.78262583414713\n",
      "     validation loss = 70.5735\n",
      "Epoch 716 finished ! Training Loss: 148.56311459011502\n",
      "     validation loss = 136.0994\n",
      "Epoch 717 finished ! Training Loss: 165.87241787380643\n",
      "     validation loss = 83.6941\n",
      "Epoch 718 finished ! Training Loss: 145.46715799967447\n",
      "     validation loss = 128.9217\n",
      "Epoch 719 finished ! Training Loss: 149.5937917497423\n",
      "     validation loss = 124.1799\n",
      "Epoch 720 finished ! Training Loss: 145.97595638699002\n",
      "     validation loss = 63.4371\n",
      "Epoch 721 finished ! Training Loss: 192.48119269476996\n",
      "     validation loss = 131.5326\n",
      "Epoch 722 finished ! Training Loss: 178.7175318400065\n",
      "     validation loss = 133.0226\n",
      "Epoch 723 finished ! Training Loss: 185.13751305474176\n",
      "     validation loss = 130.5289\n",
      "Epoch 724 finished ! Training Loss: 156.03040822347006\n",
      "     validation loss = 111.1108\n",
      "Epoch 725 finished ! Training Loss: 159.9182120429145\n",
      "     validation loss = 80.5166\n",
      "Epoch 726 finished ! Training Loss: 149.3456971910265\n",
      "     validation loss = 98.9872\n",
      "Epoch 727 finished ! Training Loss: 130.0070546468099\n",
      "     validation loss = 71.3226\n",
      "Epoch 728 finished ! Training Loss: 168.9974611070421\n",
      "     validation loss = 116.1514\n",
      "Epoch 729 finished ! Training Loss: 149.16973283555774\n",
      "     validation loss = 142.4978\n",
      "Epoch 730 finished ! Training Loss: 181.37396155463324\n",
      "     validation loss = 82.8309\n",
      "Epoch 731 finished ! Training Loss: 182.00103251139322\n",
      "     validation loss = 70.1967\n",
      "Epoch 732 finished ! Training Loss: 161.48973422580295\n",
      "     validation loss = 85.3943\n",
      "Epoch 733 finished ! Training Loss: 160.19551255967883\n",
      "     validation loss = 111.7602\n",
      "Epoch 734 finished ! Training Loss: 142.32889090643988\n",
      "     validation loss = 93.2688\n",
      "Epoch 735 finished ! Training Loss: 162.66828070746527\n",
      "     validation loss = 78.8700\n",
      "Epoch 736 finished ! Training Loss: 200.65056355794272\n",
      "     validation loss = 123.5073\n",
      "Epoch 737 finished ! Training Loss: 173.4181340535482\n",
      "     validation loss = 88.2510\n",
      "Epoch 738 finished ! Training Loss: 139.27795113457574\n",
      "     validation loss = 137.8026\n",
      "Epoch 739 finished ! Training Loss: 142.82914140489368\n",
      "     validation loss = 76.6821\n",
      "Epoch 740 finished ! Training Loss: 170.3269788953993\n",
      "     validation loss = 85.4672\n",
      "Epoch 741 finished ! Training Loss: 157.47835879855685\n",
      "     validation loss = 59.6601\n",
      "Epoch 742 finished ! Training Loss: 146.52645789252387\n",
      "     validation loss = 69.7388\n",
      "Epoch 743 finished ! Training Loss: 154.08071984185113\n",
      "     validation loss = 71.9466\n",
      "Epoch 744 finished ! Training Loss: 147.296871609158\n",
      "     validation loss = 83.7861\n",
      "Epoch 745 finished ! Training Loss: 151.15696716308594\n",
      "     validation loss = 86.6911\n",
      "Epoch 746 finished ! Training Loss: 160.3713090684679\n",
      "     validation loss = 92.7115\n",
      "Epoch 747 finished ! Training Loss: 144.27136654324002\n",
      "     validation loss = 79.8822\n",
      "Epoch 748 finished ! Training Loss: 131.6609378390842\n",
      "     validation loss = 83.2655\n",
      "Epoch 749 finished ! Training Loss: 144.99978298611111\n",
      "     validation loss = 59.4361\n",
      "Epoch 750 finished ! Training Loss: 170.30401950412326\n",
      "     validation loss = 66.3869\n",
      "Checkpoint 751 saved !\n",
      "Epoch 751 finished ! Training Loss: 170.1663941277398\n",
      "     validation loss = 85.2816\n",
      "Epoch 752 finished ! Training Loss: 133.92498440212674\n",
      "     validation loss = 66.0448\n",
      "Epoch 753 finished ! Training Loss: 140.51594967312283\n",
      "     validation loss = 72.5471\n",
      "Epoch 754 finished ! Training Loss: 164.6881349351671\n",
      "     validation loss = 51.0103\n",
      "Epoch 755 finished ! Training Loss: 144.64829762776694\n",
      "     validation loss = 66.0981\n",
      "Epoch 756 finished ! Training Loss: 158.4876454671224\n",
      "     validation loss = 85.5640\n",
      "Epoch 757 finished ! Training Loss: 163.49219852023654\n",
      "     validation loss = 96.6726\n",
      "Epoch 758 finished ! Training Loss: 123.86932796902127\n",
      "     validation loss = 113.1094\n",
      "Epoch 759 finished ! Training Loss: 124.6707403394911\n",
      "     validation loss = 63.3293\n",
      "Epoch 760 finished ! Training Loss: 131.22503492567273\n",
      "     validation loss = 60.2031\n",
      "Epoch 761 finished ! Training Loss: 138.78665754530164\n",
      "     validation loss = 81.1661\n",
      "Epoch 762 finished ! Training Loss: 125.3546125623915\n",
      "     validation loss = 61.9360\n",
      "Epoch 763 finished ! Training Loss: 125.43176693386502\n",
      "     validation loss = 65.8072\n",
      "Epoch 764 finished ! Training Loss: 123.17131084865994\n",
      "     validation loss = 68.1383\n",
      "Epoch 765 finished ! Training Loss: 135.55518129136829\n",
      "     validation loss = 67.1085\n",
      "Epoch 766 finished ! Training Loss: 176.26632351345486\n",
      "     validation loss = 70.5015\n",
      "Epoch 767 finished ! Training Loss: 120.90761354234483\n",
      "     validation loss = 70.1439\n",
      "Epoch 768 finished ! Training Loss: 154.67466735839844\n",
      "     validation loss = 67.4470\n",
      "Epoch 769 finished ! Training Loss: 107.68883344862196\n",
      "     validation loss = 71.6052\n",
      "Epoch 770 finished ! Training Loss: 144.80750528971353\n",
      "     validation loss = 59.1235\n",
      "Epoch 771 finished ! Training Loss: 118.09446716308594\n",
      "     validation loss = 61.1890\n",
      "Epoch 772 finished ! Training Loss: 135.59069781833225\n",
      "     validation loss = 66.9718\n",
      "Epoch 773 finished ! Training Loss: 131.51373418172201\n",
      "     validation loss = 60.5443\n",
      "Epoch 774 finished ! Training Loss: 145.2154901292589\n",
      "     validation loss = 45.3117\n",
      "Epoch 775 finished ! Training Loss: 122.48249944051106\n",
      "     validation loss = 64.2868\n",
      "Epoch 776 finished ! Training Loss: 143.2562895880805\n",
      "     validation loss = 74.7935\n",
      "Epoch 777 finished ! Training Loss: 123.02784898546007\n",
      "     validation loss = 54.8636\n",
      "Epoch 778 finished ! Training Loss: 113.83221096462674\n",
      "     validation loss = 95.2940\n",
      "Epoch 779 finished ! Training Loss: 117.60009087456598\n",
      "     validation loss = 112.9942\n",
      "Epoch 780 finished ! Training Loss: 133.96503575642905\n",
      "     validation loss = 62.8185\n",
      "Epoch 781 finished ! Training Loss: 112.17977481418185\n",
      "     validation loss = 65.6128\n",
      "Epoch 782 finished ! Training Loss: 119.32487784491644\n",
      "     validation loss = 78.3201\n",
      "Epoch 783 finished ! Training Loss: 104.8160400390625\n",
      "     validation loss = 124.8547\n",
      "Epoch 784 finished ! Training Loss: 116.91252687242296\n",
      "     validation loss = 53.1341\n",
      "Epoch 785 finished ! Training Loss: 129.10059865315756\n",
      "     validation loss = 70.8393\n",
      "Epoch 786 finished ! Training Loss: 126.64532046847873\n",
      "     validation loss = 56.5989\n",
      "Epoch 787 finished ! Training Loss: 138.12561204698352\n",
      "     validation loss = 56.8164\n",
      "Epoch 788 finished ! Training Loss: 112.94882032606337\n",
      "     validation loss = 55.8918\n",
      "Epoch 789 finished ! Training Loss: 122.47920354207356\n",
      "     validation loss = 84.5317\n",
      "Epoch 790 finished ! Training Loss: 149.27463658650717\n",
      "     validation loss = 70.8150\n",
      "Epoch 791 finished ! Training Loss: 122.6650144788954\n",
      "     validation loss = 90.7813\n",
      "Epoch 792 finished ! Training Loss: 142.63853878445096\n",
      "     validation loss = 96.4105\n",
      "Epoch 793 finished ! Training Loss: 140.15465545654297\n",
      "     validation loss = 64.9657\n",
      "Epoch 794 finished ! Training Loss: 120.44400066799588\n",
      "     validation loss = 88.8563\n",
      "Epoch 795 finished ! Training Loss: 127.51463911268446\n",
      "     validation loss = 66.0564\n",
      "Epoch 796 finished ! Training Loss: 142.9560423956977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     validation loss = 76.2876\n",
      "Epoch 797 finished ! Training Loss: 143.56932152642145\n",
      "     validation loss = 51.6047\n",
      "Epoch 798 finished ! Training Loss: 136.53563944498697\n",
      "     validation loss = 58.4983\n",
      "Epoch 799 finished ! Training Loss: 125.8340326944987\n",
      "     validation loss = 55.7549\n",
      "Epoch 800 finished ! Training Loss: 133.67003970675998\n",
      "     validation loss = 93.9013\n",
      "Epoch 801 finished ! Training Loss: 148.07248009575738\n",
      "     validation loss = 128.8094\n",
      "Epoch 802 finished ! Training Loss: 152.47383202446832\n",
      "     validation loss = 65.3616\n",
      "Epoch 803 finished ! Training Loss: 122.12136925591363\n",
      "     validation loss = 79.7180\n",
      "Epoch 804 finished ! Training Loss: 143.43042161729602\n",
      "     validation loss = 73.7016\n",
      "Epoch 805 finished ! Training Loss: 137.01218583848743\n",
      "     validation loss = 68.7487\n",
      "Epoch 806 finished ! Training Loss: 122.6809344821506\n",
      "     validation loss = 74.7633\n",
      "Epoch 807 finished ! Training Loss: 110.83785883585612\n",
      "     validation loss = 41.9685\n",
      "Epoch 808 finished ! Training Loss: 130.5506820678711\n",
      "     validation loss = 70.6823\n",
      "Epoch 809 finished ! Training Loss: 151.57098219129773\n",
      "     validation loss = 75.2390\n",
      "Epoch 810 finished ! Training Loss: 121.38150321112738\n",
      "     validation loss = 56.1220\n",
      "Epoch 811 finished ! Training Loss: 118.24522272745769\n",
      "     validation loss = 77.1207\n",
      "Epoch 812 finished ! Training Loss: 105.53194385104709\n",
      "     validation loss = 46.3530\n",
      "Epoch 813 finished ! Training Loss: 114.35269673665364\n",
      "     validation loss = 65.2808\n",
      "Epoch 814 finished ! Training Loss: 141.1330557929145\n",
      "     validation loss = 87.0447\n",
      "Epoch 815 finished ! Training Loss: 142.04685550265842\n",
      "     validation loss = 60.2141\n",
      "Epoch 816 finished ! Training Loss: 134.1830037434896\n",
      "     validation loss = 59.3206\n",
      "Epoch 817 finished ! Training Loss: 139.92830997043185\n",
      "     validation loss = 75.5767\n",
      "Epoch 818 finished ! Training Loss: 136.49634806315103\n",
      "     validation loss = 107.4377\n",
      "Epoch 819 finished ! Training Loss: 118.15221235487196\n",
      "     validation loss = 69.6687\n",
      "Epoch 820 finished ! Training Loss: 129.77496083577475\n",
      "     validation loss = 53.7631\n",
      "Epoch 821 finished ! Training Loss: 126.29595353868272\n",
      "     validation loss = 76.3574\n",
      "Epoch 822 finished ! Training Loss: 143.7710778978136\n",
      "     validation loss = 61.9706\n",
      "Epoch 823 finished ! Training Loss: 135.7477175394694\n",
      "     validation loss = 56.2666\n",
      "Epoch 824 finished ! Training Loss: 119.11298370361328\n",
      "     validation loss = 56.6116\n",
      "Epoch 825 finished ! Training Loss: 134.93619876437717\n",
      "     validation loss = 40.6789\n",
      "Epoch 826 finished ! Training Loss: 136.5987197028266\n",
      "     validation loss = 76.5042\n",
      "Epoch 827 finished ! Training Loss: 135.5746315850152\n",
      "     validation loss = 52.6657\n",
      "Epoch 828 finished ! Training Loss: 124.7757436964247\n",
      "     validation loss = 57.6666\n",
      "Epoch 829 finished ! Training Loss: 119.411866929796\n",
      "     validation loss = 105.6445\n",
      "Epoch 830 finished ! Training Loss: 141.50109354654947\n",
      "     validation loss = 106.4077\n",
      "Epoch 831 finished ! Training Loss: 140.34952969021268\n",
      "     validation loss = 128.1007\n",
      "Epoch 832 finished ! Training Loss: 145.33234278361002\n",
      "     validation loss = 101.9611\n",
      "Epoch 833 finished ! Training Loss: 132.69565031263562\n",
      "     validation loss = 106.2782\n",
      "Epoch 834 finished ! Training Loss: 158.32698652479382\n",
      "     validation loss = 88.9593\n",
      "Epoch 835 finished ! Training Loss: 128.89892874823676\n",
      "     validation loss = 73.9902\n",
      "Epoch 836 finished ! Training Loss: 141.61809963650174\n",
      "     validation loss = 83.5268\n",
      "Epoch 837 finished ! Training Loss: 172.89703284369574\n",
      "     validation loss = 94.5657\n",
      "Epoch 838 finished ! Training Loss: 105.04432974921332\n",
      "     validation loss = 59.4280\n",
      "Epoch 839 finished ! Training Loss: 142.2832514444987\n",
      "     validation loss = 61.8520\n",
      "Epoch 840 finished ! Training Loss: 138.75701310899524\n",
      "     validation loss = 68.4016\n",
      "Epoch 841 finished ! Training Loss: 115.0567398071289\n",
      "     validation loss = 52.0880\n",
      "Epoch 842 finished ! Training Loss: 135.13983874850803\n",
      "     validation loss = 61.2694\n",
      "Epoch 843 finished ! Training Loss: 120.2383550008138\n",
      "     validation loss = 62.2522\n",
      "Epoch 844 finished ! Training Loss: 100.87460793389215\n",
      "     validation loss = 67.5285\n",
      "Epoch 845 finished ! Training Loss: 121.25575256347656\n",
      "     validation loss = 56.1160\n",
      "Epoch 846 finished ! Training Loss: 111.41321139865451\n",
      "     validation loss = 56.3841\n",
      "Epoch 847 finished ! Training Loss: 144.16850111219617\n",
      "     validation loss = 61.0146\n",
      "Epoch 848 finished ! Training Loss: 129.2506569756402\n",
      "     validation loss = 72.8698\n",
      "Epoch 849 finished ! Training Loss: 111.2541749742296\n",
      "     validation loss = 53.3047\n",
      "Epoch 850 finished ! Training Loss: 113.58101442125108\n",
      "     validation loss = 71.8902\n",
      "Checkpoint 851 saved !\n",
      "Epoch 851 finished ! Training Loss: 124.55452558729384\n",
      "     validation loss = 125.9776\n",
      "Epoch 852 finished ! Training Loss: 121.05220497979059\n",
      "     validation loss = 74.3616\n",
      "Epoch 853 finished ! Training Loss: 127.79651090833876\n",
      "     validation loss = 62.1208\n",
      "Epoch 854 finished ! Training Loss: 124.38702138264973\n",
      "     validation loss = 50.8686\n",
      "Epoch 855 finished ! Training Loss: 97.93761401706271\n",
      "     validation loss = 49.9743\n",
      "Epoch 856 finished ! Training Loss: 161.4548585679796\n",
      "     validation loss = 72.1008\n",
      "Epoch 857 finished ! Training Loss: 112.71426476372613\n",
      "     validation loss = 49.5255\n",
      "Epoch 858 finished ! Training Loss: 105.0467775132921\n",
      "     validation loss = 53.0751\n",
      "Epoch 859 finished ! Training Loss: 112.11137602064345\n",
      "     validation loss = 45.5241\n",
      "Epoch 860 finished ! Training Loss: 143.10472191704645\n",
      "     validation loss = 84.9151\n",
      "Epoch 861 finished ! Training Loss: 113.89629024929471\n",
      "     validation loss = 60.9448\n",
      "Epoch 862 finished ! Training Loss: 129.49113082885742\n",
      "     validation loss = 44.4167\n",
      "Epoch 863 finished ! Training Loss: 116.81644354926215\n",
      "     validation loss = 52.8979\n",
      "Epoch 864 finished ! Training Loss: 131.970093621148\n",
      "     validation loss = 53.1660\n",
      "Epoch 865 finished ! Training Loss: 141.1966086493598\n",
      "     validation loss = 52.3251\n",
      "Epoch 866 finished ! Training Loss: 118.22948667738173\n",
      "     validation loss = 60.5982\n",
      "Epoch 867 finished ! Training Loss: 124.93717744615343\n",
      "     validation loss = 50.7019\n",
      "Epoch 868 finished ! Training Loss: 112.71915478176541\n",
      "     validation loss = 55.6880\n",
      "Epoch 869 finished ! Training Loss: 125.55790201822917\n",
      "     validation loss = 42.5622\n",
      "Epoch 870 finished ! Training Loss: 126.46433300442166\n",
      "     validation loss = 50.2402\n",
      "Epoch 871 finished ! Training Loss: 119.28169250488281\n",
      "     validation loss = 62.3403\n",
      "Epoch 872 finished ! Training Loss: 124.07319090101454\n",
      "     validation loss = 58.2081\n",
      "Epoch 873 finished ! Training Loss: 108.03599166870117\n",
      "     validation loss = 52.6226\n",
      "Epoch 874 finished ! Training Loss: 125.22569190131293\n",
      "     validation loss = 42.8055\n",
      "Epoch 875 finished ! Training Loss: 93.44267569647894\n",
      "     validation loss = 55.0425\n",
      "Epoch 876 finished ! Training Loss: 120.98993301391602\n",
      "     validation loss = 61.9148\n",
      "Epoch 877 finished ! Training Loss: 124.3480690850152\n",
      "     validation loss = 41.3450\n",
      "Epoch 878 finished ! Training Loss: 109.56720055474176\n",
      "     validation loss = 56.5887\n",
      "Epoch 879 finished ! Training Loss: 121.76478110419379\n",
      "     validation loss = 45.5184\n",
      "Epoch 880 finished ! Training Loss: 125.75601959228516\n",
      "     validation loss = 70.9725\n",
      "Epoch 881 finished ! Training Loss: 120.64739396837022\n",
      "     validation loss = 54.7308\n",
      "Epoch 882 finished ! Training Loss: 117.77904891967773\n",
      "     validation loss = 49.1339\n",
      "Epoch 883 finished ! Training Loss: 120.65728293524847\n",
      "     validation loss = 44.6564\n",
      "Epoch 884 finished ! Training Loss: 117.97497855292426\n",
      "     validation loss = 55.9064\n",
      "Epoch 885 finished ! Training Loss: 136.68549813164606\n",
      "     validation loss = 66.2407\n",
      "Epoch 886 finished ! Training Loss: 114.17656792534723\n",
      "     validation loss = 36.4387\n",
      "Epoch 887 finished ! Training Loss: 116.67405234442816\n",
      "     validation loss = 51.9467\n",
      "Epoch 888 finished ! Training Loss: 106.94667137993707\n",
      "     validation loss = 72.6542\n",
      "Epoch 889 finished ! Training Loss: 141.13621266682944\n",
      "     validation loss = 68.2733\n",
      "Epoch 890 finished ! Training Loss: 135.9549149407281\n",
      "     validation loss = 52.2438\n",
      "Epoch 891 finished ! Training Loss: 116.81717046101888\n",
      "     validation loss = 56.2181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892 finished ! Training Loss: 126.1908425225152\n",
      "     validation loss = 57.0550\n",
      "Epoch 893 finished ! Training Loss: 126.65455500284831\n",
      "     validation loss = 57.6058\n",
      "Epoch 894 finished ! Training Loss: 134.50270165337457\n",
      "     validation loss = 60.6133\n",
      "Epoch 895 finished ! Training Loss: 121.28860855102539\n",
      "     validation loss = 57.0276\n",
      "Epoch 896 finished ! Training Loss: 133.06022135416666\n",
      "     validation loss = 58.6913\n",
      "Epoch 897 finished ! Training Loss: 107.89890882703993\n",
      "     validation loss = 84.3360\n",
      "Epoch 898 finished ! Training Loss: 113.38502036200629\n",
      "     validation loss = 63.5748\n",
      "Epoch 899 finished ! Training Loss: 115.74192640516493\n",
      "     validation loss = 63.2825\n",
      "Epoch 900 finished ! Training Loss: 111.2618637084961\n",
      "     validation loss = 72.0284\n",
      "Checkpoint 901 saved !\n",
      "Epoch 901 finished ! Training Loss: 90.96461232503255\n",
      "     validation loss = 51.0269\n",
      "Epoch 902 finished ! Training Loss: 131.134157816569\n",
      "     validation loss = 74.0868\n",
      "Epoch 903 finished ! Training Loss: 120.7260971069336\n",
      "     validation loss = 50.2548\n",
      "Epoch 904 finished ! Training Loss: 102.7649637858073\n",
      "     validation loss = 69.1673\n",
      "Epoch 905 finished ! Training Loss: 141.898622724745\n",
      "     validation loss = 63.9762\n",
      "Epoch 906 finished ! Training Loss: 119.67256588406033\n",
      "     validation loss = 53.5385\n",
      "Epoch 907 finished ! Training Loss: 123.34771389431424\n",
      "     validation loss = 49.8929\n",
      "Epoch 908 finished ! Training Loss: 111.21980624728732\n",
      "     validation loss = 45.0634\n",
      "Epoch 909 finished ! Training Loss: 135.8475752936469\n",
      "     validation loss = 57.2788\n",
      "Epoch 910 finished ! Training Loss: 108.40055423312717\n",
      "     validation loss = 86.6554\n",
      "Epoch 911 finished ! Training Loss: 141.73907894558377\n",
      "     validation loss = 87.4238\n",
      "Epoch 912 finished ! Training Loss: 97.02493031819661\n",
      "     validation loss = 87.6661\n",
      "Epoch 913 finished ! Training Loss: 106.78637907240126\n",
      "     validation loss = 65.2290\n",
      "Epoch 914 finished ! Training Loss: 108.49772771199544\n",
      "     validation loss = 52.9061\n",
      "Epoch 915 finished ! Training Loss: 113.9647462632921\n",
      "     validation loss = 45.1763\n",
      "Epoch 916 finished ! Training Loss: 122.85714509752061\n",
      "     validation loss = 60.9214\n",
      "Epoch 917 finished ! Training Loss: 123.41094504462347\n",
      "     validation loss = 57.8870\n",
      "Epoch 918 finished ! Training Loss: 97.41149054633246\n",
      "     validation loss = 81.8723\n",
      "Epoch 919 finished ! Training Loss: 122.5628170437283\n",
      "     validation loss = 97.2144\n",
      "Epoch 920 finished ! Training Loss: 150.9230965508355\n",
      "     validation loss = 54.8943\n",
      "Epoch 921 finished ! Training Loss: 105.13470247056749\n",
      "     validation loss = 46.8202\n",
      "Epoch 922 finished ! Training Loss: 98.87958145141602\n",
      "     validation loss = 65.4648\n",
      "Epoch 923 finished ! Training Loss: 121.63175455729167\n",
      "     validation loss = 64.1701\n",
      "Epoch 924 finished ! Training Loss: 119.97191789415147\n",
      "     validation loss = 67.5987\n",
      "Epoch 925 finished ! Training Loss: 112.2962383694119\n",
      "     validation loss = 67.7234\n",
      "Epoch 926 finished ! Training Loss: 100.19858805338542\n",
      "     validation loss = 74.8904\n",
      "Epoch 927 finished ! Training Loss: 111.7379976908366\n",
      "     validation loss = 78.1533\n",
      "Epoch 928 finished ! Training Loss: 88.62090810139973\n",
      "     validation loss = 68.6583\n",
      "Epoch 929 finished ! Training Loss: 144.08131323920355\n",
      "     validation loss = 40.8836\n",
      "Epoch 930 finished ! Training Loss: 115.40519883897569\n",
      "     validation loss = 55.5721\n",
      "Epoch 931 finished ! Training Loss: 137.46529557969836\n",
      "     validation loss = 54.3133\n",
      "Epoch 932 finished ! Training Loss: 112.51404274834528\n",
      "     validation loss = 44.2605\n",
      "Epoch 933 finished ! Training Loss: 115.47836642795139\n",
      "     validation loss = 45.7946\n",
      "Epoch 934 finished ! Training Loss: 96.72621578640408\n",
      "     validation loss = 75.7456\n",
      "Epoch 935 finished ! Training Loss: 147.62533230251736\n",
      "     validation loss = 58.0929\n",
      "Epoch 936 finished ! Training Loss: 123.78695085313585\n",
      "     validation loss = 63.9796\n",
      "Epoch 937 finished ! Training Loss: 126.11826027764215\n",
      "     validation loss = 75.3439\n",
      "Epoch 938 finished ! Training Loss: 120.67527898152669\n",
      "     validation loss = 91.4119\n",
      "Epoch 939 finished ! Training Loss: 99.4529389275445\n",
      "     validation loss = 54.2322\n",
      "Epoch 940 finished ! Training Loss: 111.74661848280165\n",
      "     validation loss = 44.0938\n",
      "Epoch 941 finished ! Training Loss: 143.0487535264757\n",
      "     validation loss = 56.2494\n",
      "Epoch 942 finished ! Training Loss: 109.61312018500433\n",
      "     validation loss = 82.6374\n",
      "Epoch 943 finished ! Training Loss: 125.42257351345486\n",
      "     validation loss = 54.5071\n",
      "Epoch 944 finished ! Training Loss: 135.94026311238608\n",
      "     validation loss = 79.9806\n",
      "Epoch 945 finished ! Training Loss: 146.24446190728082\n",
      "     validation loss = 60.9839\n",
      "Epoch 946 finished ! Training Loss: 107.78633965386285\n",
      "     validation loss = 61.4835\n",
      "Epoch 947 finished ! Training Loss: 124.35726589626736\n",
      "     validation loss = 73.5551\n",
      "Epoch 948 finished ! Training Loss: 129.36216820610895\n",
      "     validation loss = 81.8455\n",
      "Epoch 949 finished ! Training Loss: 114.44069798787434\n",
      "     validation loss = 60.8080\n",
      "Epoch 950 finished ! Training Loss: 107.72068193223741\n",
      "     validation loss = 50.2534\n"
     ]
    }
   ],
   "source": [
    "#-------------------------NEW MODEL INIT WEIGHT--------------------------------------#\n",
    "\n",
    "from loss import *\n",
    "\n",
    "train(model, train_loader, validation_loader, optimizer, scheduler,\\\n",
    "      device=device, dtype=dtype, lossFun=MSE, epochs=1500, startepoch=701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------SAVE THE MODEL STATE DICT----------------------------------#\n",
    "PATH = 'LNET-404.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch 1.0 CUDA 10.1",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
