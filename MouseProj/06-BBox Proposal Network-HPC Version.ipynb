{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. BBox Regression Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from dataset import *\n",
    "from vnet import *\n",
    "from training import *\n",
    "from niiutility import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup Torch Global Variable, load memory map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#------------------------------- GLOBAL VARIABLES -------------------------------------#\n",
    "\n",
    "USE_GPU = True\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 6\n",
    "NUM_TRAIN = 279\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BvMaskDataset, return image and bbox tuple of 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------LOAD THE DATA SET-------------------------------------------#\n",
    "regen = False\n",
    "\n",
    "if regen:\n",
    "    data_index = np.arange(370) + 1\n",
    "    data_idnex = np.stack ([np.random.shuffle(data_index[:259]),np.random.shuffle(data_index[259:])])\n",
    "    print(list(data_index))\n",
    "else:\n",
    "    data_index = np.array ([55, 185, 236, 156, 150, 32, 116, 249, 142, 120, 53, 19, 179, 161, 68, 173, 181, 125,\n",
    "                            183, 113, 69, 149, 196, 123, 22, 48, 233, 70, 28, 89, 86, 225, 180, 208, 223, 155, 97,\n",
    "                            76, 186, 80, 228, 184, 170, 103, 231, 232, 41, 234, 187, 137, 117, 25, 147, 139, 202,\n",
    "                            102, 54, 104, 81, 128, 105, 198, 66, 30, 135, 119, 110, 247, 153, 211, 85, 61, 251,\n",
    "                            50, 93, 2, 239, 6, 101, 122, 3, 136, 212, 10, 46, 82, 51, 188, 190, 15, 7, 206, 248,\n",
    "                            226, 71, 169, 201, 214, 216, 159, 107, 152, 20, 224, 29, 59, 154, 243, 227, 189, 192,\n",
    "                            33, 79, 16, 114, 144, 26, 98, 245, 4, 141, 62, 132, 39, 191, 121, 171, 220, 115, 96,\n",
    "                            126, 24, 176, 75, 252, 194, 112, 197, 134, 218, 127, 158, 235, 67, 210, 178, 258, 177,\n",
    "                            219, 204, 13, 44, 160, 195, 92, 83, 174, 5, 250, 37, 162, 143, 241, 9, 18, 146, 14, 31,\n",
    "                            242, 91, 43, 217, 230, 151, 209, 23, 199, 35, 90, 45, 47, 148, 87, 165, 88, 129, 52, 246,\n",
    "                            193, 73, 108, 17, 111, 124, 99, 109, 140, 130, 100, 240, 229, 237, 253, 94, 72, 34, 238,\n",
    "                            213, 11, 254, 64, 78, 42, 49, 207, 168, 56, 259, 65, 58, 74, 8, 57, 257, 131, 205, 215, 222,\n",
    "                            175, 145, 27, 36, 163, 244, 255, 38, 157, 60, 203, 63, 95, 1, 84, 12, 167, 166, 256, 118, 133,\n",
    "                            200, 221, 172, 40, 182, 138, 77, 21, 106, 164, 343, 342, 303, 284, 317, 319, 313, 362, 275,\n",
    "                            294, 320, 348, 333, 290, 266, 325, 278, 367, 350, 340, 289, 267, 310, 268, 287, 337, 298,\n",
    "                            270, 286, 276, 368, 304, 311, 269, 295, 363, 321, 291, 309, 345, 263, 281, 329, 271, 273,\n",
    "                            352, 323, 360, 283, 297, 338, 300, 344, 366, 261, 358, 302, 369, 292, 315, 364, 306, 361,\n",
    "                            346, 318, 305, 307, 351, 260, 277, 332, 314, 328, 341, 288, 262, 316, 299, 327, 293, 312,\n",
    "                            354, 285, 347, 359, 331, 274, 357, 324, 370, 265, 349, 280, 272, 339, 336, 308, 356, 282,\n",
    "                            330, 296, 334, 365, 335, 301, 264, 353, 279, 326, 355, 322])\n",
    "    \n",
    "dataset_trans = DatasetBV(data_index, \n",
    "                         transform=transforms.Compose([\n",
    "                             downSample(4),\n",
    "                             RandomFilp(0.5),\n",
    "                             RandomAffine(180, 5, 1)\n",
    "                         ])\n",
    "                     )\n",
    "\n",
    "#-------------------------CREATE DATA LOADER FOR TRAIN AND VAL------------------------#\n",
    "\n",
    "data_size = len(dataset_trans)\n",
    "train_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE, \\\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE,\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,data_size)),\\\n",
    "                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print first 4 batch of data\n",
    "* 3 order = 122.30930733680725\n",
    "* 2 order = 91.09534621238708\n",
    "* 1 order = 69.77253293991089\n",
    "* 0 order = 62.877673387527466\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(), \\\n",
    "          sample_batched['label'].size())\n",
    "    show_batch_image(sample_batched['image'],BATCH_SIZE,None)\n",
    "    print(sample_batched['label'])\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnet import LNet\n",
    "\n",
    "LoadCKP = False\n",
    "\n",
    "CKPPath = 'checkpoint2019-04-05 19:46:58.793496.pth'\n",
    "\n",
    "model = LNet(img_size=(64, 64, 64), out_size=6)\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, verbose=True)\n",
    "logger = {'train':[], 'validation':[]}\n",
    "\n",
    "if LoadCKP:\n",
    "    loadckp(model, optimizer, scheduler, logger, CKPPath, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------NEW MODEL INIT WEIGHT--------------------------------------#\n",
    "\n",
    "from loss import *\n",
    "\n",
    "train(model, train_loader, validation_loader, optimizer, scheduler,\\\n",
    "      device=device, dtype=dtype, lossFun=MSE, logger=logger, epochs=5000, startepoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------SAVE THE MODEL STATE DICT----------------------------------#\n",
    "PATH = 'LNET-404.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IVP",
   "language": "python",
   "name": "cs231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
