{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. BBox Regression Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from dataset import *\n",
    "from vnet import *\n",
    "from training import *\n",
    "from niiutility import show_image, show_batch_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup Torch Global Variable, load memory map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#------------------------------- GLOBAL VARIABLES -------------------------------------#\n",
    "\n",
    "USE_GPU = True\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 6\n",
    "NUM_TRAIN = 80\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BvMaskDataset, return image and bbox tuple of 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------LOAD THE DATA SET-------------------------------------------#\n",
    "regen = False\n",
    "\n",
    "if regen:\n",
    "\n",
    "    data_index = np.arange(107)\n",
    "    data_index = np.delete(data_index, 46)\n",
    "    data_idnex = np.random.shuffle(data_index)\n",
    "else:\n",
    "    data_index = np.array ([50,17,81,39,36,88,33,77,7,1,52,43,34,40,41,18,72,58,51,\n",
    "                  63,78,35,16,79,0,89,70,67,60,13,76,8,2,47,4,97,29,85,32,\n",
    "                  55,30,49,44,11,101,22,37,10,92,68,5,64,105,95,20,38,99,\n",
    "                  84,86,91,96,71,98,104,45,69,103,27,19,59,73,106,93,24,80,\n",
    "                  66,28,90,3,102,31,26,94,62,54,48,12,61,87,42,65,74,53,57,\n",
    "                  14,56,83,100,25,6,75,82,23,9,21,15])\n",
    "    \n",
    "dataset_trans = BvMaskDataset(data_index, \n",
    "                         transform=transforms.Compose([\n",
    "                             RandomFilp(0.5),\n",
    "                             RandomAffine(180, 15, 1.2),\n",
    "                             downSample(2)\n",
    "                         ])\n",
    "                     )\n",
    "\n",
    "#-------------------------CREATE DATA LOADER FOR TRAIN AND VAL------------------------#\n",
    "\n",
    "data_size = len(dataset_trans)\n",
    "train_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE, \\\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\\\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(dataset_trans, batch_size=BATCH_SIZE,\n",
    "                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,data_size)),\\\n",
    "                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print first 4 batch of data\n",
    "* 3 order = 122.30930733680725\n",
    "* 2 order = 91.09534621238708\n",
    "* 1 order = 69.77253293991089\n",
    "* 0 order = 62.877673387527466\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched['image'].size(), \\\n",
    "          sample_batched['label'].size())\n",
    "    show_batch_image(sample_batched['image'],BATCH_SIZE,None)\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnet import LNet\n",
    "\n",
    "LoadCKP = False\n",
    "\n",
    "CKPPath = 'checkpoint2019-04-05 19:46:58.793496.pth'\n",
    "\n",
    "model = LNet(img_size=(96, 128, 128), out_size=6)\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=50, verbose=True)\n",
    "logger = {'train':[], 'validation':[]}\n",
    "\n",
    "if LoadCKP:\n",
    "    loadckp(model, optimizer, scheduler, logger, CKPPath, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7298,  0.6960, -0.7008,  0.9925, -0.1024, -1.4198],\n",
      "        [-0.9775,  0.5178, -0.5540,  1.2607,  0.4399, -2.6942]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7294,  0.5654, -1.7060,  1.6617, -0.3513, -0.7787],\n",
      "        [-0.3513,  1.1362,  0.7750,  0.4383,  0.3758, -1.4214]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.2132,  0.6925,  0.6533,  1.7403,  0.6038, -0.6992],\n",
      "        [-0.6640,  2.1095,  0.2848,  3.5039,  0.7753,  0.2882]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8067, 2.1718, 1.4174, 2.8032, 2.2962, 0.2943],\n",
      "        [0.9946, 3.0748, 1.4138, 2.5076, 1.2758, 1.0482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[1.8938, 2.9097, 1.1648, 3.1720, 2.0141, 1.7143],\n",
      "        [2.1762, 4.0688, 2.5639, 3.6860, 2.1755, 2.2929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[1.6426, 4.2055, 1.2775, 3.5374, 2.5030, 2.0919],\n",
      "        [3.5191, 4.2996, 2.5890, 5.7291, 4.1019, 2.3330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[4.0345, 5.7153, 5.0922, 5.5382, 5.2349, 3.9506],\n",
      "        [4.1187, 4.9964, 2.6112, 5.0904, 2.8142, 1.8186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[4.8643, 6.7230, 3.6236, 5.5061, 5.2931, 4.3931],\n",
      "        [5.4854, 7.9557, 6.3933, 7.5553, 6.4110, 4.8393]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[3.8099, 5.2756, 5.4772, 5.4741, 4.7794, 5.6537],\n",
      "        [6.5919, 8.0424, 6.8172, 8.2055, 6.0292, 6.7113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[7.6254, 8.4420, 7.3511, 9.6604, 7.9309, 6.7049],\n",
      "        [6.1394, 8.8017, 6.8048, 8.7228, 6.2048, 6.6282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[5.7803, 7.7139, 5.4973, 8.8527, 6.6779, 7.1462],\n",
      "        [8.8456, 8.6563, 7.1136, 9.5816, 8.5272, 7.1005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[10.5672, 10.6100,  9.8035, 11.4152, 10.8211,  9.9348],\n",
      "        [ 8.6780, 11.7479,  6.6866,  9.3267,  8.1551,  7.9679]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[10.6987, 12.1291, 11.4479, 13.5378, 12.4280,  9.1846],\n",
      "        [ 8.1566, 10.8463,  8.0583, 10.4829, 10.3130, 10.2152]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 9.5586, 12.2122,  9.6783, 13.1394, 11.0695, 11.4113],\n",
      "        [11.9733, 12.8126, 11.3059, 14.2496, 14.4970, 11.3489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 9.9127, 14.0232, 10.7092, 14.0528, 12.2983, 13.5953],\n",
      "        [14.2365, 15.2580, 13.2293, 15.9494, 14.5781, 13.8577]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[11.9876, 15.4689, 11.8240, 14.9823, 13.2829, 14.3253],\n",
      "        [14.0707, 15.9406, 13.8100, 18.1970, 16.4228, 15.0916]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[11.0327, 15.0606, 12.5214, 16.7503, 14.0318, 14.0039],\n",
      "        [15.8573, 19.2637, 16.6812, 19.0152, 18.2189, 16.3095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[12.9631, 17.7977, 14.0697, 16.4047, 15.1287, 16.1757],\n",
      "        [16.8226, 18.9984, 16.5739, 20.8542, 19.5001, 18.0652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[19.3907, 23.6064, 20.7141, 22.8360, 22.9876, 20.9201],\n",
      "        [14.7859, 19.4707, 15.4382, 20.6659, 17.4435, 19.2542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[13.0290, 17.8850, 13.7719, 17.1657, 16.7013, 15.2773],\n",
      "        [17.0814, 22.6654, 20.2195, 24.8223, 21.4269, 21.5918]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[15.4625, 19.2228, 16.0788, 20.8560, 18.2479, 18.9100],\n",
      "        [21.3429, 25.9418, 24.1650, 27.4593, 24.2195, 24.2739]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[16.9857, 22.2538, 19.9918, 23.6348, 20.7088, 23.8693],\n",
      "        [19.1810, 24.2206, 22.6996, 25.6314, 23.1692, 22.6493]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[18.7019, 24.3670, 19.8294, 26.9779, 22.8074, 26.1910],\n",
      "        [22.2577, 28.4825, 24.6494, 28.6695, 25.8017, 26.3613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[19.1292, 25.6807, 21.1656, 26.4330, 23.6566, 26.3591],\n",
      "        [24.2354, 28.7932, 26.8240, 30.8405, 27.6954, 29.4544]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[20.9759, 28.9133, 23.9218, 30.0133, 27.2475, 29.4146],\n",
      "        [21.4736, 28.9086, 23.9797, 28.0544, 26.9382, 24.6259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[20.3640, 27.9095, 23.3827, 29.4763, 26.8408, 28.0201],\n",
      "        [24.4520, 33.8347, 28.8493, 33.6695, 32.2665, 32.0737]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[26.1357, 32.9572, 29.5079, 35.8818, 30.9242, 34.8238],\n",
      "        [21.1661, 27.8127, 23.8351, 28.9275, 26.7808, 28.6512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[22.0080, 30.5896, 25.2276, 30.3563, 29.8226, 31.0300],\n",
      "        [26.8207, 35.5844, 33.0178, 37.7493, 33.1069, 35.5509]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[25.2733, 36.2244, 30.7998, 37.7665, 32.4300, 36.1456],\n",
      "        [32.3266, 41.5831, 38.4527, 43.5491, 39.0058, 40.2117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[30.6994, 41.7279, 38.1068, 41.3644, 35.7562, 40.9887],\n",
      "        [25.6692, 33.3568, 27.2070, 34.7213, 29.5875, 33.0660]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e13ba4044641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train(model, train_loader, validation_loader, optimizer, scheduler,\\\n\u001b[0;32m----> 6\u001b[0;31m       device=device, dtype=dtype, lossFun=MSE, logger=logger, epochs=5000, startepoch=0)\n\u001b[0m",
      "\u001b[0;32m/scratch/tx506/ECE-GY-6123-IMAGE-AND-VIDEO-PROCESSING/MouseProj/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, traindata, valdata, optimizer, scheduler, device, dtype, lossFun, logger, epochs, startepoch, usescheduler)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#-------------------------NEW MODEL INIT WEIGHT--------------------------------------#\n",
    "\n",
    "from loss import *\n",
    "\n",
    "train(model, train_loader, validation_loader, optimizer, scheduler,\\\n",
    "      device=device, dtype=dtype, lossFun=MSE, logger=logger, epochs=5000, startepoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------SAVE THE MODEL STATE DICT----------------------------------#\n",
    "PATH = 'LNET-404.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
